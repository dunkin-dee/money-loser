{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2248527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rex\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://rex:#Pass123@localhost/new_ml\")\n",
    "\n",
    "all_pairs = [\n",
    "\"AUDCAD\",\n",
    "\"AUDCHF\",\n",
    "\"AUDJPY\",\n",
    "\"AUDNZD\",\n",
    "\"AUDUSD\",\n",
    "\"CADCHF\",\n",
    "\"CADJPY\",\n",
    "\"CHFJPY\",\n",
    "\"EURAUD\",\n",
    "\"EURCAD\",\n",
    "\"EURCHF\",\n",
    "\"EURGBP\",\n",
    "\"EURJPY\",\n",
    "\"EURUSD\",\n",
    "\"GBPAUD\",\n",
    "\"GBPCAD\",\n",
    "\"GBPCHF\",\n",
    "\"GBPJPY\",\n",
    "\"GBPNZD\",\n",
    "\"GBPUSD\",\n",
    "\"NZDCAD\",\n",
    "\"NZDCHF\",\n",
    "\"NZDJPY\",\n",
    "\"NZDUSD\",\n",
    "\"USDCAD\",\n",
    "\"USDCHF\",\n",
    "\"USDJPY\"\n",
    "]\n",
    "\n",
    "\n",
    "def add_dict_to_df(base_df, my_dict, prefix):\n",
    "    \"\"\"\n",
    "    takes the dataframe to be added to, the dictionary to be added and prefix for column names and returns dataframe with added\n",
    "    columns\n",
    "    \"\"\"\n",
    "    my_df =  pd.DataFrame.from_dict(my_dict, orient=\"index\")\n",
    "    for col_name in my_df.columns:\n",
    "        my_df.rename({col_name: prefix+col_name}, axis=1, inplace=True)\n",
    "    return(pd.concat([base_df, my_df], axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f4714d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on AUDCAD hourly\n",
      "Creating audcad_1h\n",
      "Working on AUDCAD 4 hourly\n",
      "Creating audcad_4h\n"
     ]
    }
   ],
   "source": [
    "for pair in all_pairs:\n",
    "    print(f\"Working on {pair} hourly\")\n",
    "    \n",
    "    sqlh = f\"SELECT * FROM `{pair.lower()}_1h` ORDER BY `index` ASC\"\n",
    "    df = pd.read_sql(sqlh, engine, index_col=\"index\")\n",
    "\n",
    "    singles = rex.get_single_candlestick_patterns(df)\n",
    "    all_singles = []\n",
    "    for x in singles.keys():\n",
    "        all_singles = all_singles + singles[x]\n",
    "    all_singles = set(all_singles)\n",
    "    all_singles = sorted(list(all_singles))\n",
    "    singles_series = pd.Series(dtype=\"float\")\n",
    "    for x in range(len(df)):\n",
    "        if df.iloc[x].name in all_singles:\n",
    "            singles_series.loc[df.iloc[x].name] = 1\n",
    "        else:\n",
    "            singles_series.loc[df.iloc[x].name] = 0\n",
    "    df.insert(len(df.columns), \"singles\", singles_series)\n",
    "\n",
    "    doubles = rex.get_double_candlestick_patterns(df)\n",
    "    bull_doubles = doubles[\"bullish\"]\n",
    "    bear_doubles = doubles[\"bearish\"]\n",
    "    all_bull_doubles = []\n",
    "    all_bear_doubles = []\n",
    "    for x in bull_doubles.keys():\n",
    "        all_bull_doubles = all_bull_doubles + bull_doubles[x]\n",
    "    all_bull_doubles = set(all_bull_doubles)\n",
    "    all_bull_doubles = sorted(list(all_bull_doubles))\n",
    "    bull_doubles_series = pd.Series(dtype=\"float\")\n",
    "    for x in range(len(df)):\n",
    "        if df.iloc[x].name in all_bull_doubles:\n",
    "            bull_doubles_series.loc[df.iloc[x].name] = 1\n",
    "        else:\n",
    "            bull_doubles_series.loc[df.iloc[x].name] = 0\n",
    "    df.insert(len(df.columns), \"bull_doubles\", bull_doubles_series)\n",
    "    for x in bear_doubles.keys():\n",
    "        all_bear_doubles = all_bear_doubles + bear_doubles[x]\n",
    "    all_bear_doubles = set(all_bear_doubles)\n",
    "    all_bear_doubles = sorted(list(all_bear_doubles))\n",
    "    bear_doubles_series = pd.Series(dtype=\"float\")\n",
    "    for x in range(len(df)):\n",
    "        if df.iloc[x].name in all_bear_doubles:\n",
    "            bear_doubles_series.loc[df.iloc[x].name] = 1\n",
    "        else:\n",
    "            bear_doubles_series.loc[df.iloc[x].name] = 0\n",
    "    df.insert(len(df.columns), \"bear_doubles\", bear_doubles_series)\n",
    "    \n",
    "    triples = rex.get_triple_candlestick_patterns(df)\n",
    "    bull_triples = triples[\"bullish\"]\n",
    "    bear_triples = triples[\"bearish\"]\n",
    "    bull_triples = bull_triples | bear_triples\n",
    "    bull_dict = {}\n",
    "\n",
    "\n",
    "    #getting timestamps from tuples in returned dictionaries\n",
    "    for bull_type in bull_triples.keys():\n",
    "        temp_list = []\n",
    "        try:\n",
    "            for temp_tuple in bull_triples[bull_type]:\n",
    "                temp_list.append(temp_tuple[0])\n",
    "            bull_dict[bull_type] = temp_list\n",
    "        except IndexError:\n",
    "            df[bull_type] = 0\n",
    "    #adding to dataframes 1 for each column where pattern appears\n",
    "    for bull_type in bull_dict.keys():\n",
    "        df[bull_type] = 0\n",
    "        for index in bull_dict[bull_type]:\n",
    "            df.loc[index, bull_type] = 1\n",
    "    \n",
    "\n",
    "    tp = rex.get_turns(df)\n",
    "    tp_keys = sorted(list(tp.keys()))\n",
    "    level_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        stop_point = tp_keys[0]\n",
    "        stop_point = next((x for x in tp_keys if x > index ), None)\n",
    "        if stop_point:\n",
    "            tp_index = tp_keys.index(stop_point)\n",
    "            if tp_index > 4:\n",
    "                level_list = []\n",
    "                working_keys = tp_keys[tp_index-5:tp_index]\n",
    "                for some_key in working_keys:\n",
    "                    #getting the 5 levels, dependent on movement of turn\n",
    "                    if tp[some_key] == \"up\":\n",
    "                        level_list.append(min([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "                    else:\n",
    "                        level_list.append(max([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "                level_dict[index] = {\"level_1\": level_list[0],\n",
    "                                     \"level_2\": level_list[1],\n",
    "                                     \"level_3\": level_list[2],\n",
    "                                     \"level_4\": level_list[3],\n",
    "                                     \"level_5\": level_list[4]}\n",
    "        else:\n",
    "            level_list = []\n",
    "            working_keys = tp_keys[-5:]\n",
    "            for some_key in working_keys:\n",
    "                #getting the 5 levels, dependent on movement of turn\n",
    "                if tp[some_key] == \"up\":\n",
    "                    level_list.append(min([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "                else:\n",
    "                    level_list.append(max([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "            level_dict[index] = {\"level_1\": level_list[0],\n",
    "                                 \"level_2\": level_list[1],\n",
    "                                 \"level_3\": level_list[2],\n",
    "                                 \"level_4\": level_list[3],\n",
    "                                 \"level_5\": level_list[4]}\n",
    "    tp_levels_df = pd.DataFrame.from_dict(level_dict, orient=\"index\")\n",
    "    df = pd.concat([df, tp_levels_df], axis=1)\n",
    "\n",
    "    sqld = f\"SELECT * FROM `{pair.lower()}_d` ORDER BY `index` ASC\"\n",
    "    df_d = pd.read_sql(sqld, engine, index_col=\"index\")\n",
    "\n",
    "\n",
    "    daily_keys = sorted(list(df_d.index))\n",
    "    pp_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        today_index = daily_keys.index(pd.Timestamp(pd.to_datetime(index).date()))\n",
    "        if today_index > 0:\n",
    "            yesterday = daily_keys[today_index-1]\n",
    "            yesterdict = {\"open\": df_d.loc[yesterday, \"open\"],\n",
    "                          \"high\": df_d.loc[yesterday, \"high\"],\n",
    "                          \"low\": df_d.loc[yesterday, \"low\"],\n",
    "                          \"close\": df_d.loc[yesterday, \"close\"]}\n",
    "            all_pp = rex.get_pp_daily(yesterdict)\n",
    "            pp_dict[index] = {\"pp\" : all_pp[\"daily\"][\"standard\"][\"pp\"],\n",
    "                              \"standard_r1\" : all_pp[\"daily\"][\"standard\"][\"r1\"],\n",
    "                              \"standard_s1\" : all_pp[\"daily\"][\"standard\"][\"s1\"],\n",
    "                              \"fib_r1\" : all_pp[\"daily\"][\"fibonacci\"][\"r1\"],\n",
    "                              \"fib_s1\" : all_pp[\"daily\"][\"fibonacci\"][\"s1\"],}\n",
    "    pp_df = pd.DataFrame.from_dict(pp_dict,orient='index')\n",
    "    df = pd.concat([df, pp_df], axis=1)\n",
    "\n",
    "    for ma in [5 ,10]:\n",
    "        sma = rex.get_sma(df, ma)\n",
    "        ema = rex.get_ema(df, ma)\n",
    "        df = pd.concat([df, pd.Series(sma).to_frame(f\"sma{ma}\"), pd.Series(ema).to_frame(f\"ema{ma}\")], axis=1)\n",
    "\n",
    "    bb = rex.get_bollinger(df)\n",
    "    df = add_dict_to_df(df, bb, \"bb_\")\n",
    "\n",
    "    kelt = rex.get_keltner(df)\n",
    "    df = add_dict_to_df(df, kelt, \"kelt_\")\n",
    "\n",
    "    macd = rex.get_macd(df)\n",
    "    df = add_dict_to_df(df, macd, \"macd_\")\n",
    "\n",
    "    rsi = rex.get_rsi(df)\n",
    "    df = pd.concat([df, pd.Series(rsi).to_frame(\"rsi\")], axis=1)\n",
    "\n",
    "    psar = rex.get_parabolic_sar(df)\n",
    "    df = add_dict_to_df(df, psar, \"psar_\")\n",
    "\n",
    "    stoch = rex.get_stochastic(df)\n",
    "    df = add_dict_to_df(df, stoch, \"stoch_\")\n",
    "\n",
    "    adx = rex.get_adx(df)\n",
    "    df = add_dict_to_df(df, adx, \"adx_\")\n",
    "\n",
    "    will = rex.get_williams_r(df)\n",
    "    df = pd.concat([df, pd.Series(will).to_frame(\"williams\")], axis=1)\n",
    "\n",
    "    turns = rex.get_turns(df)\n",
    "    turns_keys = sorted(list(turns.keys()))\n",
    "    turns_series = pd.Series(dtype=\"object\")\n",
    "    for index, row in df.iterrows():\n",
    "        stop_time = next((x for x in turns_keys if x > index), None)\n",
    "        if stop_time:\n",
    "            future_index = turns_keys.index(stop_time)\n",
    "            if future_index > 0:\n",
    "                use_time = turns_keys[future_index-1]\n",
    "                turns_series.loc[index] = turns[use_time]\n",
    "        else:\n",
    "            turns_series[index] = turns[turns_keys[-1]]\n",
    "    df = pd.concat([df, turns_series.shift(3).to_frame('curr_trend')], axis=1)\n",
    "    \n",
    "    #getting 3 and 6 period sums of signed bodysizes\n",
    "    df['bodysize'] = np.where(df['direction'] == \"up\" , df[\"bodysize\"], (df[\"bodysize\"]*-1))\n",
    "    for list_iter in range(1, 6):\n",
    "        temp_df = df[\"bodysize\", \"wick\", \"shadow\"]\n",
    "        temp_df.rename({\"bodysize\":\"bodysize\"+str(list_iter),\n",
    "                        \"wick\":\"wick\"+str(list_iter),\n",
    "                        \"shadow\":\"shadow\"+str(list_iter)}, axis=1, inplace=True)\n",
    "        df = pd.concat([df, temp_df], axis=1)\n",
    "        \n",
    "    df[\"bs3\"] = df[\"bodysize\"] + df[\"bodysize1\"] +df[\"bodysize2\"]\n",
    "    df[\"bs6\"] = df[\"bs3\"] + df[\"bodysize3\"] + df[\"bodysize4\"] + df[\"bodysize5\"]\n",
    "    df[\"w3\"] = (df[\"wick\"] + df[\"wick1\"] + df[\"wick2\"])/3\n",
    "    df[\"w6\"] = (df[\"wick\"] + df[\"wick1\"] + df[\"wick2\"] + df[\"wick3\"] + df[\"wick4\"] + df[\"wick5\"])/6\n",
    "    df[\"s3\"] = (df[\"shadow\"] + df[\"shadow1\"] + df[\"shadow2\"])/3\n",
    "    df[\"s6\"] = (df[\"shadow\"] + df[\"shadow1\"] + df[\"shadow2\"] + df[\"shadow3\"] + df[\"shadow4\"] + df[\"shadow5\"])/6\n",
    "        \n",
    "    \n",
    "\n",
    "    df = pd.concat([df.drop([\"direction\", \"curr_trend\", \"psar_direction\"], axis=1), \n",
    "                    pd.get_dummies(df[[\"direction\", \"curr_trend\",\"psar_direction\"]])], axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    table_name_h = (pair+\"_1h\").lower()\n",
    "    print(\"Creating \"+table_name_h)\n",
    "    df.to_sql(table_name_h, con=engine, if_exists='replace', index=True)\n",
    "    with engine.connect() as con:\n",
    "        con.execute('ALTER TABLE `%s` ADD PRIMARY KEY(`index`)'%table_name_h)\n",
    "        \n",
    "        \n",
    "    #Now for 4 hour table\n",
    "    ###########################################################################################\n",
    "    ###########################################################################################\n",
    "    ###########################################################################################\n",
    "    \n",
    "    sql4h = f\"SELECT * FROM `{pair.lower()}_4h` ORDER BY `index` ASC\"\n",
    "    df = pd.read_sql(sql4h, engine, index_col=\"index\")\n",
    "\n",
    "    singles = rex.get_single_candlestick_patterns(df)\n",
    "    all_singles = []\n",
    "    for x in singles.keys():\n",
    "        all_singles = all_singles + singles[x]\n",
    "    all_singles = set(all_singles)\n",
    "    all_singles = sorted(list(all_singles))\n",
    "    singles_series = pd.Series(dtype=\"float\")\n",
    "    for x in range(len(df)):\n",
    "        if df.iloc[x].name in all_singles:\n",
    "            singles_series.loc[df.iloc[x].name] = 1\n",
    "        else:\n",
    "            singles_series.loc[df.iloc[x].name] = 0\n",
    "    df.insert(len(df.columns), \"singles\", singles_series)\n",
    "\n",
    "    doubles = rex.get_double_candlestick_patterns(df)\n",
    "    bull_doubles = doubles[\"bullish\"]\n",
    "    bear_doubles = doubles[\"bearish\"]\n",
    "    all_bull_doubles = []\n",
    "    all_bear_doubles = []\n",
    "    for x in bull_doubles.keys():\n",
    "        all_bull_doubles = all_bull_doubles + bull_doubles[x]\n",
    "    all_bull_doubles = set(all_bull_doubles)\n",
    "    all_bull_doubles = sorted(list(all_bull_doubles))\n",
    "    bull_doubles_series = pd.Series(dtype=\"float\")\n",
    "    for x in range(len(df)):\n",
    "        if df.iloc[x].name in all_bull_doubles:\n",
    "            bull_doubles_series.loc[df.iloc[x].name] = 1\n",
    "        else:\n",
    "            bull_doubles_series.loc[df.iloc[x].name] = 0\n",
    "    df.insert(len(df.columns), \"bull_doubles\", bull_doubles_series)\n",
    "    for x in bear_doubles.keys():\n",
    "        all_bear_doubles = all_bear_doubles + bear_doubles[x]\n",
    "    all_bear_doubles = set(all_bear_doubles)\n",
    "    all_bear_doubles = sorted(list(all_bear_doubles))\n",
    "    bear_doubles_series = pd.Series(dtype=\"float\")\n",
    "    for x in range(len(df)):\n",
    "        if df.iloc[x].name in all_bear_doubles:\n",
    "            bear_doubles_series.loc[df.iloc[x].name] = 1\n",
    "        else:\n",
    "            bear_doubles_series.loc[df.iloc[x].name] = 0\n",
    "    df.insert(len(df.columns), \"bear_doubles\", bear_doubles_series)\n",
    "    \n",
    "    triples = rex.get_triple_candlestick_patterns(df)\n",
    "    bull_triples = triples[\"bullish\"]\n",
    "    bear_triples = triples[\"bearish\"]\n",
    "    bull_triples = bull_triples | bear_triples\n",
    "    bull_dict = {}\n",
    "    for bull_type in bull_triples.keys():\n",
    "        temp_list = []\n",
    "        try:\n",
    "            for temp_tuple in bull_triples[bull_type]:\n",
    "                temp_list.append(temp_tuple[0])\n",
    "            bull_dict[bull_type] = temp_list\n",
    "        except IndexError:\n",
    "            df[bull_type] = 0\n",
    "    for bull_type in bull_dict.keys():\n",
    "        df[bull_type] = 0\n",
    "        for index in bull_dict[bull_type]:\n",
    "            df.loc[index, bull_type] = 1\n",
    "\n",
    "    tp = rex.get_turns(df)\n",
    "    tp_keys = sorted(list(tp.keys()))\n",
    "    level_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        stop_point = tp_keys[0]\n",
    "        stop_point = next((x for x in tp_keys if x > index ), None)\n",
    "        if stop_point:\n",
    "            tp_index = tp_keys.index(stop_point)\n",
    "            if tp_index > 4:\n",
    "                level_list = []\n",
    "                working_keys = tp_keys[tp_index-5:tp_index]\n",
    "                for some_key in working_keys:\n",
    "                    #getting the 5 levels, dependent on movement of turn\n",
    "                    if tp[some_key] == \"up\":\n",
    "                        level_list.append(min([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "                    else:\n",
    "                        level_list.append(max([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "                level_dict[index] = {\"level_1\": level_list[0],\n",
    "                                     \"level_2\": level_list[1],\n",
    "                                     \"level_3\": level_list[2],\n",
    "                                     \"level_4\": level_list[3],\n",
    "                                     \"level_5\": level_list[4]}\n",
    "        else:\n",
    "            level_list = []\n",
    "            working_keys = tp_keys[-5:]\n",
    "            for some_key in working_keys:\n",
    "                #getting the 5 levels, dependent on movement of turn\n",
    "                if tp[some_key] == \"up\":\n",
    "                    level_list.append(min([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "                else:\n",
    "                    level_list.append(max([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "            level_dict[index] = {\"level_1\": level_list[0],\n",
    "                                 \"level_2\": level_list[1],\n",
    "                                 \"level_3\": level_list[2],\n",
    "                                 \"level_4\": level_list[3],\n",
    "                                 \"level_5\": level_list[4]}\n",
    "    tp_levels_df = pd.DataFrame.from_dict(level_dict, orient=\"index\")\n",
    "    df = pd.concat([df, tp_levels_df], axis=1)\n",
    "\n",
    "    daily_keys = sorted(list(df_d.index))\n",
    "    pp_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        today_index = daily_keys.index(pd.Timestamp(pd.to_datetime(index).date()))\n",
    "        if today_index > 0:\n",
    "            yesterday = daily_keys[today_index-1]\n",
    "            yesterdict = {\"open\": df_d.loc[yesterday, \"open\"],\n",
    "                          \"high\": df_d.loc[yesterday, \"high\"],\n",
    "                          \"low\": df_d.loc[yesterday, \"low\"],\n",
    "                          \"close\": df_d.loc[yesterday, \"close\"]}\n",
    "            all_pp = rex.get_pp_daily(yesterdict)\n",
    "            pp_dict[index] = {\"pp\" : all_pp[\"daily\"][\"standard\"][\"pp\"],\n",
    "                              \"standard_r1\" : all_pp[\"daily\"][\"standard\"][\"r1\"],\n",
    "                              \"standard_s1\" : all_pp[\"daily\"][\"standard\"][\"s1\"],\n",
    "                              \"fib_r1\" : all_pp[\"daily\"][\"fibonacci\"][\"r1\"],\n",
    "                              \"fib_s1\" : all_pp[\"daily\"][\"fibonacci\"][\"s1\"],}\n",
    "    pp_df = pd.DataFrame.from_dict(pp_dict,orient='index')\n",
    "    df = pd.concat([df, pp_df], axis=1)\n",
    "\n",
    "    for ma in [5 ,10]:\n",
    "        sma = rex.get_sma(df, ma)\n",
    "        ema = rex.get_ema(df, ma)\n",
    "        df = pd.concat([df, pd.Series(sma).to_frame(f\"sma{ma}\"), pd.Series(ema).to_frame(f\"ema{ma}\")], axis=1)\n",
    "\n",
    "    bb = rex.get_bollinger(df)\n",
    "    df = add_dict_to_df(df, bb, \"bb_\")\n",
    "\n",
    "    kelt = rex.get_keltner(df)\n",
    "    df = add_dict_to_df(df, kelt, \"kelt_\")\n",
    "\n",
    "    macd = rex.get_macd(df)\n",
    "    df = add_dict_to_df(df, macd, \"macd_\")\n",
    "\n",
    "    rsi = rex.get_rsi(df)\n",
    "    df = pd.concat([df, pd.Series(rsi).to_frame(\"rsi\")], axis=1)\n",
    "\n",
    "    psar = rex.get_parabolic_sar(df)\n",
    "    df = add_dict_to_df(df, psar, \"psar_\")\n",
    "\n",
    "    stoch = rex.get_stochastic(df)\n",
    "    df = add_dict_to_df(df, stoch, \"stoch_\")\n",
    "\n",
    "    adx = rex.get_adx(df)\n",
    "    df = add_dict_to_df(df, adx, \"adx_\")\n",
    "\n",
    "    will = rex.get_williams_r(df)\n",
    "    df = pd.concat([df, pd.Series(will).to_frame(\"williams\")], axis=1)\n",
    "\n",
    "    turns = rex.get_turns(df)\n",
    "    turns_keys = sorted(list(turns.keys()))\n",
    "    turns_series = pd.Series(dtype=\"object\")\n",
    "    for index, row in df.iterrows():\n",
    "        stop_time = next((x for x in turns_keys if x > index), None)\n",
    "        if stop_time:\n",
    "            future_index = turns_keys.index(stop_time)\n",
    "            if future_index > 0:\n",
    "                use_time = turns_keys[future_index-1]\n",
    "                turns_series.loc[index] = turns[use_time]\n",
    "        else:\n",
    "            turns_series[index] = turns[turns_keys[-1]]\n",
    "    df = pd.concat([df, turns_series.shift(3).to_frame('curr_trend')], axis=1)\n",
    "    \n",
    "    #getting 3 and 6 period sums of signed bodysizes\n",
    "    df['bodysize'] = np.where(df['direction'] == \"up\" , df[\"bodysize\"], (df[\"bodysize\"]*-1))\n",
    "    for list_iter in range(1, 6):\n",
    "        temp_df = df[\"bodysize\", \"wick\", \"shadow\"]\n",
    "        temp_df.rename({\"bodysize\":\"bodysize\"+str(list_iter),\n",
    "                        \"wick\":\"wick\"+str(list_iter),\n",
    "                        \"shadow\":\"shadow\"+str(list_iter)}, axis=1, inplace=True)\n",
    "        df = pd.concat([df, temp_df], axis=1)\n",
    "        \n",
    "    df[\"bs3\"] = df[\"bodysize\"] + df[\"bodysize1\"] +df[\"bodysize2\"]\n",
    "    df[\"bs6\"] = df[\"bs3\"] + df[\"bodysize3\"] + df[\"bodysize4\"] + df[\"bodysize5\"]\n",
    "    df[\"w3\"] = (df[\"wick\"] + df[\"wick1\"] + df[\"wick2\"])/3\n",
    "    df[\"w6\"] = (df[\"wick\"] + df[\"wick1\"] + df[\"wick2\"] + df[\"wick3\"] + df[\"wick4\"] + df[\"wick5\"])/6\n",
    "    df[\"s3\"] = (df[\"shadow\"] + df[\"shadow1\"] + df[\"shadow2\"])/3\n",
    "    df[\"s6\"] = (df[\"shadow\"] + df[\"shadow1\"] + df[\"shadow2\"] + df[\"shadow3\"] + df[\"shadow4\"] + df[\"shadow5\"])/6\n",
    "\n",
    "    df = pd.concat([df.drop([\"direction\", \"curr_trend\", \"psar_direction\"], axis=1), \n",
    "                    pd.get_dummies(df[[\"direction\", \"curr_trend\",\"psar_direction\"]])], axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    table_name_h = (pair+\"_4h\").lower()\n",
    "    print(\"Creating \"+table_name_h)\n",
    "    df.to_sql(table_name_h, engine, if_exists='replace', index=True)\n",
    "    with engine.connect() as con:\n",
    "        con.execute('ALTER TABLE `%s` ADD PRIMARY KEY(`index`)'%table_name_h)\n",
    "        \n",
    "    ### Daily tables\n",
    "    #########################################################################################################################\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    print(f\"Working on {pair} daily\")\n",
    "    sqld = f\"SELECT * FROM `{pair.lower()}_d` ORDER BY `index` ASC\"\n",
    "    df_d = pd.read_sql(sqld, engine, index_col=\"index\")\n",
    "\n",
    "    singles = rex.get_single_candlestick_patterns(df)\n",
    "    all_singles = []\n",
    "    for x in singles.keys():\n",
    "        all_singles = all_singles + singles[x]\n",
    "    all_singles = set(all_singles)\n",
    "    all_singles = sorted(list(all_singles))\n",
    "    singles_series = pd.Series(dtype=\"float\")\n",
    "    for x in range(len(df)):\n",
    "        if df.iloc[x].name in all_singles:\n",
    "            singles_series.loc[df.iloc[x].name] = 1\n",
    "        else:\n",
    "            singles_series.loc[df.iloc[x].name] = 0\n",
    "    df.insert(len(df.columns), \"singles\", singles_series)\n",
    "\n",
    "    doubles = rex.get_double_candlestick_patterns(df)\n",
    "    bull_doubles = doubles[\"bullish\"]\n",
    "    bear_doubles = doubles[\"bearish\"]\n",
    "    all_bull_doubles = []\n",
    "    all_bear_doubles = []\n",
    "    for x in bull_doubles.keys():\n",
    "        all_bull_doubles = all_bull_doubles + bull_doubles[x]\n",
    "    all_bull_doubles = set(all_bull_doubles)\n",
    "    all_bull_doubles = sorted(list(all_bull_doubles))\n",
    "    bull_doubles_series = pd.Series(dtype=\"float\")\n",
    "    for x in range(len(df)):\n",
    "        if df.iloc[x].name in all_bull_doubles:\n",
    "            bull_doubles_series.loc[df.iloc[x].name] = 1\n",
    "        else:\n",
    "            bull_doubles_series.loc[df.iloc[x].name] = 0\n",
    "    df.insert(len(df.columns), \"bull_doubles\", bull_doubles_series)\n",
    "    for x in bear_doubles.keys():\n",
    "        all_bear_doubles = all_bear_doubles + bear_doubles[x]\n",
    "    all_bear_doubles = set(all_bear_doubles)\n",
    "    all_bear_doubles = sorted(list(all_bear_doubles))\n",
    "    bear_doubles_series = pd.Series(dtype=\"float\")\n",
    "    for x in range(len(df)):\n",
    "        if df.iloc[x].name in all_bear_doubles:\n",
    "            bear_doubles_series.loc[df.iloc[x].name] = 1\n",
    "        else:\n",
    "            bear_doubles_series.loc[df.iloc[x].name] = 0\n",
    "    df.insert(len(df.columns), \"bear_doubles\", bear_doubles_series)\n",
    "    \n",
    "    triples = rex.get_triple_candlestick_patterns(df)\n",
    "    bull_triples = triples[\"bullish\"]\n",
    "    bear_triples = triples[\"bearish\"]\n",
    "    bull_triples = bull_triples | bear_triples\n",
    "    bull_dict = {}\n",
    "    for bull_type in bull_triples.keys():\n",
    "        temp_list = []\n",
    "        try:\n",
    "            for temp_tuple in bull_triples[bull_type]:\n",
    "                temp_list.append(temp_tuple[0])\n",
    "            bull_dict[bull_type] = temp_list\n",
    "        except IndexError:\n",
    "            df[bull_type] = 0\n",
    "    for bull_type in bull_dict.keys():\n",
    "        df[bull_type] = 0\n",
    "        for index in bull_dict[bull_type]:\n",
    "            df.loc[index, bull_type] = 1\n",
    "\n",
    "    tp = rex.get_turns(df)\n",
    "    tp_keys = sorted(list(tp.keys()))\n",
    "    level_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        stop_point = tp_keys[0]\n",
    "        stop_point = next((x for x in tp_keys if x > index ), None)\n",
    "        if stop_point:\n",
    "            tp_index = tp_keys.index(stop_point)\n",
    "            if tp_index > 4:\n",
    "                level_list = []\n",
    "                working_keys = tp_keys[tp_index-5:tp_index]\n",
    "                for some_key in working_keys:\n",
    "                    #getting the 5 levels, dependent on movement of turn\n",
    "                    if tp[some_key] == \"up\":\n",
    "                        level_list.append(min([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "                    else:\n",
    "                        level_list.append(max([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "                level_dict[index] = {\"level_1\": level_list[0],\n",
    "                                     \"level_2\": level_list[1],\n",
    "                                     \"level_3\": level_list[2],\n",
    "                                     \"level_4\": level_list[3],\n",
    "                                     \"level_5\": level_list[4]}\n",
    "        else:\n",
    "            level_list = []\n",
    "            working_keys = tp_keys[-5:]\n",
    "            for some_key in working_keys:\n",
    "                #getting the 5 levels, dependent on movement of turn\n",
    "                if tp[some_key] == \"up\":\n",
    "                    level_list.append(min([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "                else:\n",
    "                    level_list.append(max([float(df.loc[some_key, \"open\"]), float(df.loc[some_key, \"close\"])]))\n",
    "            level_dict[index] = {\"level_1\": level_list[0],\n",
    "                                 \"level_2\": level_list[1],\n",
    "                                 \"level_3\": level_list[2],\n",
    "                                 \"level_4\": level_list[3],\n",
    "                                 \"level_5\": level_list[4]}\n",
    "    tp_levels_df = pd.DataFrame.from_dict(level_dict, orient=\"index\")\n",
    "    df = pd.concat([df, tp_levels_df], axis=1)\n",
    "\n",
    "    \n",
    "    for ma in [5 ,10]:\n",
    "        sma = rex.get_sma(df, ma)\n",
    "        ema = rex.get_ema(df, ma)\n",
    "        df = pd.concat([df, pd.Series(sma).to_frame(f\"sma{ma}\"), pd.Series(ema).to_frame(f\"ema{ma}\")], axis=1)\n",
    "\n",
    "    bb = rex.get_bollinger(df)\n",
    "    df = add_dict_to_df(df, bb, \"bb_\")\n",
    "\n",
    "    kelt = rex.get_keltner(df)\n",
    "    df = add_dict_to_df(df, kelt, \"kelt_\")\n",
    "\n",
    "    macd = rex.get_macd(df)\n",
    "    df = add_dict_to_df(df, macd, \"macd_\")\n",
    "\n",
    "    rsi = rex.get_rsi(df)\n",
    "    df = pd.concat([df, pd.Series(rsi).to_frame(\"rsi\")], axis=1)\n",
    "\n",
    "    psar = rex.get_parabolic_sar(df)\n",
    "    df = add_dict_to_df(df, psar, \"psar_\")\n",
    "\n",
    "    stoch = rex.get_stochastic(df)\n",
    "    df = add_dict_to_df(df, stoch, \"stoch_\")\n",
    "\n",
    "    adx = rex.get_adx(df)\n",
    "    df = add_dict_to_df(df, adx, \"adx_\")\n",
    "\n",
    "    will = rex.get_williams_r(df)\n",
    "    df = pd.concat([df, pd.Series(will).to_frame(\"williams\")], axis=1)\n",
    "\n",
    "    turns = rex.get_turns(df)\n",
    "    turns_keys = sorted(list(turns.keys()))\n",
    "    turns_series = pd.Series(dtype=\"object\")\n",
    "    for index, row in df.iterrows():\n",
    "        stop_time = next((x for x in turns_keys if x > index), None)\n",
    "        if stop_time:\n",
    "            future_index = turns_keys.index(stop_time)\n",
    "            if future_index > 0:\n",
    "                use_time = turns_keys[future_index-1]\n",
    "                turns_series.loc[index] = turns[use_time]\n",
    "        else:\n",
    "            turns_series[index] = turns[turns_keys[-1]]\n",
    "    df = pd.concat([df, turns_series.shift(3).to_frame('curr_trend')], axis=1)\n",
    "    \n",
    "    df['bodysize'] = np.where(df['direction'] == \"up\" , df[\"bodysize\"], (df[\"bodysize\"]*-1))\n",
    "    for list_iter in range(1, 6):\n",
    "        temp_df = df[\"bodysize\", \"wick\", \"shadow\"]\n",
    "        temp_df.rename({\"bodysize\":\"bodysize\"+str(list_iter),\n",
    "                        \"wick\":\"wick\"+str(list_iter),\n",
    "                        \"shadow\":\"shadow\"+str(list_iter)}, axis=1, inplace=True)\n",
    "        df = pd.concat([df, temp_df], axis=1)\n",
    "        \n",
    "    df[\"bs3\"] = df[\"bodysize\"] + df[\"bodysize1\"] +df[\"bodysize2\"]\n",
    "    df[\"bs6\"] = df[\"bs3\"] + df[\"bodysize3\"] + df[\"bodysize4\"] + df[\"bodysize5\"]\n",
    "    df[\"w3\"] = (df[\"wick\"] + df[\"wick1\"] + df[\"wick2\"])/3\n",
    "    df[\"w6\"] = (df[\"wick\"] + df[\"wick1\"] + df[\"wick2\"] + df[\"wick3\"] + df[\"wick4\"] + df[\"wick5\"])/6\n",
    "    df[\"s3\"] = (df[\"shadow\"] + df[\"shadow1\"] + df[\"shadow2\"])/3\n",
    "    df[\"s6\"] = (df[\"shadow\"] + df[\"shadow1\"] + df[\"shadow2\"] + df[\"shadow3\"] + df[\"shadow4\"] + df[\"shadow5\"])/6\n",
    "\n",
    "    df = pd.concat([df.drop([\"direction\", \"curr_trend\", \"psar_direction\"], axis=1), \n",
    "                    pd.get_dummies(df[[\"direction\", \"curr_trend\",\"psar_direction\"]])], axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    table_name_h = (pair+\"_1d\").lower()\n",
    "    print(\"Creating \"+table_name_h)\n",
    "    df.to_sql(table_name_h, engine, if_exists='replace', index=True)\n",
    "    with engine.connect() as con:\n",
    "        con.execute('ALTER TABLE `%s` ADD PRIMARY KEY(`index`)'%table_name_h)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "298f8e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2013-09-24 10:00:00', '2013-09-24 11:00:00', '2013-09-24 12:00:00',\n",
       "       '2013-09-24 13:00:00', '2013-09-24 14:00:00', '2013-09-24 15:00:00',\n",
       "       '2013-09-24 16:00:00', '2013-09-24 17:00:00', '2013-09-24 18:00:00',\n",
       "       '2013-09-24 19:00:00', '2013-09-24 20:00:00', '2013-09-24 21:00:00',\n",
       "       '2013-09-24 22:00:00', '2013-09-24 23:00:00', '2013-09-25 00:00:00',\n",
       "       '2013-09-25 01:00:00', '2013-09-25 02:00:00', '2013-09-25 03:00:00',\n",
       "       '2013-09-25 04:00:00', '2013-09-25 05:00:00', '2013-09-25 06:00:00',\n",
       "       '2013-09-25 07:00:00', '2013-09-25 08:00:00', '2013-09-25 09:00:00',\n",
       "       '2013-09-25 10:00:00', '2013-09-25 11:00:00', '2013-09-25 12:00:00',\n",
       "       '2013-09-25 13:00:00', '2013-09-25 14:00:00', '2013-09-25 15:00:00',\n",
       "       '2013-09-25 16:00:00', '2013-09-25 17:00:00', '2013-09-25 18:00:00',\n",
       "       '2013-09-25 19:00:00', '2013-09-25 20:00:00', '2013-09-25 21:00:00',\n",
       "       '2013-09-25 22:00:00', '2013-09-25 23:00:00', '2013-09-26 00:00:00',\n",
       "       '2013-09-26 01:00:00', '2013-09-26 02:00:00', '2013-09-26 03:00:00',\n",
       "       '2013-09-26 04:00:00', '2013-09-26 05:00:00', '2013-09-26 06:00:00',\n",
       "       '2013-09-26 07:00:00', '2013-09-26 08:00:00', '2013-09-26 09:00:00',\n",
       "       '2013-09-26 10:00:00', '2013-09-26 11:00:00', '2013-09-26 12:00:00',\n",
       "       '2013-09-26 13:00:00', '2013-09-26 14:00:00', '2013-09-26 15:00:00',\n",
       "       '2013-09-26 16:00:00', '2013-09-26 17:00:00', '2013-09-26 18:00:00',\n",
       "       '2013-09-26 19:00:00', '2013-09-26 20:00:00', '2013-09-26 21:00:00',\n",
       "       '2013-09-26 22:00:00', '2013-09-26 23:00:00', '2013-09-27 00:00:00',\n",
       "       '2013-09-27 01:00:00', '2013-09-27 02:00:00', '2013-09-27 03:00:00',\n",
       "       '2013-09-27 04:00:00'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfd92f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
